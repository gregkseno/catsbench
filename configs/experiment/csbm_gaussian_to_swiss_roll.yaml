# @package _global_

defaults:
  - override /data: toy
  - override /model: simple_mlp
  - override /method: csbm
  - override /callbacks: [rich_progress_bar, model_summary, toy_metric_callback]
  - override /logger: wandb
  - override /trainer: gpu
  - _self_

data:
  dim: 2
  num_categories: 50
  train_val_test_split: [0.8, 0.1, 0.1]
  batch_size: 512 
  num_workers: 0
  pin_memory: false
  input_dataset:
    _target_: src.data.toy.DiscreteGaussianDataset
    _partial_: true
    dim: ${data.dim}
    num_categories: ${data.num_categories}
  target_dataset:
    _target_: src.data.toy.DiscreteSwissRollDataset
    _partial_: true
    noise: 0.8
    num_categories: ${data.num_categories}

model:
  timestep_dim: 2
  layers: [128, 128, 128]

prior:
  alpha: 0.02
  prior_type: gaussian
  num_timesteps: 10
  num_skip_steps: 10

method:
  use_mini_batch: false
  num_first_iterations: 10
  kl_loss_coeff: 1.0
  ce_loss_coeff: 0.001
  mse_loss_coeff: 0
  ignore_index: -100

trainer:
  limit_train_batches: 20000 # controls number of IMF inner iterations
  val_check_interval: 1000
  accumulate_grad_batches: 1
  gradient_clip_val: null